{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"keys.cfg\")\n",
    "consumer_secret = config.get(\"Twitter\", \"consumer_secret\")\n",
    "consumer_token = config.get(\"Twitter\", \"consumer_token\")\n",
    "token_key = config.get(\"Twitter\", \"token_key\")\n",
    "token_secret = config.get(\"Twitter\", \"token_secret\")\n",
    "auth = tweepy.OAuthHandler(consumer_token, consumer_secret)\n",
    "auth.set_access_token(token_key, token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools \n",
    "from tweepy import Cursor as C_\n",
    "topics = [\"NO_TOPIC\"]\n",
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "df = pd.DataFrame(columns=cols)\n",
    "n_tweets = 100\n",
    "\n",
    "for topic, tweet in itertools.product(topics, C_(api.search, topic, lang='en').items(n_tweets)):\n",
    "    if len(tweet.text) > 3:\n",
    "        vals = [-1, tweet.id, tweet.created_at, topic, tweet.user.name, tweet.text]\n",
    "        df = df.append([pd.Series(vals, index=cols)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/new_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with existing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "new_df = pd.read_csv(\"data/new_dataset.csv\", sep=\";\")\n",
    "new_df = new_df[new_df['sentiment'] != -1]\n",
    "train_df = pd.read_csv(\"data/sentiment140/training.1600000.processed.noemoticon.csv\", header=None, names=cols, encoding=\"ISO-8859-1\")\n",
    "test_df = pd.read_csv(\"data/sentiment140/testdata.manual.2009.06.14.csv\", header=None, names=cols, encoding=\"ISO-8859-1\")\n",
    "df = pd.concat([train_df, test_df, new_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/merge_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
